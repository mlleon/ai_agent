{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa006045-b40f-469f-b71b-d1afbc0e3b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from zhipuai import ZhipuAI\n",
    "from IPython.display import display, Code, Markdown\n",
    "import requests\n",
    "import json\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6ff0e67-0115-40c9-8dbc-fb92aba834f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 外部函数python解释器\n",
    "def python_inter(py_code, g='globals()'):\n",
    "    \"\"\"\n",
    "    专门用于执行非绘图类python代码，并获取最终查询或处理结果。若是设计绘图操作的Python代码，则需要调用fig_inter函数来执行。\n",
    "    :param py_code: 字符串形式的Python代码，用于执行对telco_db数据库中各张数据表进行操作\n",
    "    :param g: g，字符串形式变量，表示环境变量，无需设置，保持默认参数即可\n",
    "    :return：代码运行的最终结果\n",
    "    \"\"\"\n",
    "\n",
    "    global_vars_before = set(g.keys())\n",
    "    try:\n",
    "        exec(py_code, g)\n",
    "    except Exception as e:\n",
    "        return f\"代码执行时报错{e}\"\n",
    "    global_vars_after = set(g.keys())\n",
    "    new_vars = global_vars_after - global_vars_before\n",
    "    # 若存在新变量\n",
    "    if new_vars:\n",
    "        result = {var: g[var] for var in new_vars}\n",
    "        return str(result)\n",
    "    # 若不存在新变量，即有可能是代码是表达式，也有可能代码对相同变量重复赋值\n",
    "    else:\n",
    "        try:\n",
    "            # 尝试如果是表达式，则返回表达式运行结果\n",
    "            return str(eval(py_code, g))\n",
    "        # 若报错，则先测试是否是对相同变量重复赋值\n",
    "        except Exception as e:\n",
    "            try:\n",
    "                exec(py_code, g)\n",
    "                return \"已经顺利执行代码\"\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            # 若不是重复赋值，则报错\n",
    "            return f\"代码执行时报错{e}\"\n",
    "\n",
    "\n",
    "def get_glm_response(messages,\n",
    "                     tools=None,\n",
    "                     model='glm-4'):\n",
    "    \"\"\"\n",
    "    单次GLM模型响应函数，能够正常获取模型响应，并在模型无法正常响应时暂停模型调用，\\\n",
    "    并在休息一分钟之后继续调用模型。最多尝试三次。\n",
    "    :param messages: 必要参数，字典类型，输入到Chat模型的messages参数对象\n",
    "    :param tools: 可选参数，默认为None，可以设置为包含全部外部函数参数解释Schema格式列表\n",
    "    :param model: Chat模型，可选参数，默认模型为glm-4\n",
    "    :return：Chat模型输出结果\n",
    "    \"\"\"\n",
    "    attempts = 0\n",
    "    max_attempts = 3\n",
    "\n",
    "    api_key = os.getenv(\"ZHIPU_API_KEY\")\n",
    "    client = ZhipuAI(api_key=api_key)\n",
    "\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,  # 使用函数参数\n",
    "                tools=tools,\n",
    "            )\n",
    "            return response  # 成功时返回响应\n",
    "        except Exception as e:  # 捕获所有异常\n",
    "            print(f\"发生错误：{e}\")\n",
    "            attempts += 1\n",
    "            if attempts < max_attempts:\n",
    "                print(\"等待1分钟后重试...\")\n",
    "                time.sleep(60)  # 等待1分钟\n",
    "            else:\n",
    "                print(\"尝试次数过多，停止尝试。\")\n",
    "                return None  # 在所有尝试后返回 None\n",
    "\n",
    "\n",
    "def check_code_run(messages,\n",
    "                   functions_list=None,\n",
    "                   tools=None,\n",
    "                   model=\"glm-4\",\n",
    "                   auto_run=True):\n",
    "    \"\"\"\n",
    "    能够自动执行外部函数调用的Chat对话模型，专门用于代码解释器的构建过程，可以通过auto_run参数设置，决定是否自动执行代码\n",
    "    :param messages: 必要参数，字典类型，输入到Chat模型的messages参数对象\n",
    "    :param functions_list: 可选参数，默认为None，可以设置为包含全部外部函数的列表对象\n",
    "    :param tools: 可选参数，默认为None，可以设置为包含全部外部函数参数解释Schema格式列表\n",
    "    :param model: Chat模型，可选参数，默认模型为glm-4\n",
    "    :auto_run：在调用外部函数的情况下，是否自动进行Second Response。该参数只在外部函数存在时起作用\n",
    "    :return：Chat模型输出结果\n",
    "    \"\"\"\n",
    "\n",
    "    # 如果没有外部函数库，则执行普通的对话任务\n",
    "    if tools is None:\n",
    "        response = get_glm_response(\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            model=model\n",
    "        )\n",
    "        response_message = response.choices[0].message\n",
    "\n",
    "    # 若存在外部函数库，则需要灵活选取外部函数并进行回答\n",
    "    else:\n",
    "        # 创建外部函数库字典\n",
    "        available_functions = {func.__name__: func for func in functions_list}\n",
    "\n",
    "        # first response\n",
    "        response = get_glm_response(\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            model=model\n",
    "        )\n",
    "        response_message = response.choices[0].message\n",
    "\n",
    "        # 判断返回结果是否存在function_call，即判断是否需要调用外部函数来回答问题\n",
    "        # 若存在function_call，则执行Function calling流程\n",
    "        # 需要调用外部函数，由于考虑到可能存在多次Function calling情况，这里创建While循环\n",
    "        # While循环停止条件：response_message不包含function_call\n",
    "        while response_message.tool_calls is not None:\n",
    "            print(\"正在调用外部函数...\")\n",
    "            # 获取函数名\n",
    "            function_name = response_message.tool_calls[0].function.name\n",
    "            # 获取函数对象\n",
    "            fuction_to_call = available_functions[function_name]\n",
    "            try:\n",
    "                # 获取函数参数\n",
    "                function_args = json.loads(response_message.tool_calls[0].function.arguments)\n",
    "                # 将当前操作空间中的全局变量添加到外部函数中\n",
    "                function_args['g'] = globals()\n",
    "\n",
    "                def convert_to_markdown(code, language):\n",
    "                    return f\"```{language}\\n{code}\\n```\"\n",
    "\n",
    "                if function_args.get('py_code'):\n",
    "                    code = function_args['py_code']\n",
    "                    markdown_code = convert_to_markdown(code, 'python')\n",
    "                    print(\"即将执行以下代码：\")\n",
    "\n",
    "                else:\n",
    "                    markdown_code = function_args\n",
    "\n",
    "                display(Markdown(markdown_code))\n",
    "\n",
    "                if not auto_run:\n",
    "                    res = input('请确认是否运行上述代码（1），或者退出本次运行过程（2）')\n",
    "\n",
    "                    if res == '2':\n",
    "                        print(\"终止运行\")\n",
    "                        return None\n",
    "\n",
    "                print(\"正在执行代码，请稍后...\")\n",
    "\n",
    "                # 将函数参数输入到函数中，获取函数计算结果\n",
    "                function_response = fuction_to_call(**function_args)\n",
    "\n",
    "                print(\"外部函数已运行完毕\")\n",
    "\n",
    "                # messages中拼接first response消息\n",
    "                messages.append(response_message.model_dump())\n",
    "                # messages中拼接函数输出结果\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"content\": function_response,\n",
    "                        \"tool_call_id\": response_message.tool_calls[0].id\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # 第二次调用模型\n",
    "                second_response = get_glm_response(\n",
    "                    messages=messages,\n",
    "                    tools=tools,\n",
    "                    model=model\n",
    "                )\n",
    "\n",
    "                # 更新response_message\n",
    "                response_message = second_response.choices[0].message\n",
    "\n",
    "            except Exception as e:\n",
    "                print(\"json格式对象创建失败，正在重新运行\")\n",
    "                messages = check_code_run(messages=messages,\n",
    "                                          functions_list=functions_list,\n",
    "                                          tools=tools,\n",
    "                                          model=model,\n",
    "                                          auto_run=auto_run)\n",
    "                return messages\n",
    "\n",
    "    # While条件不满足，或执行完While循环之后，提取返回结果\n",
    "    final_response = response_message\n",
    "\n",
    "    display(Markdown(final_response.content))\n",
    "\n",
    "    messages.append(final_response.model_dump())\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f2a851-940b-438c-982d-c88488acb6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编写python解释器方法说明\n",
    "python_inter_function_info = {\n",
    "    'name': 'python_inter',\n",
    "    'description': '专门用于python代码，并获取最终查询或处理结果。',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "            'py_code': {\n",
    "                'type': 'string',\n",
    "                'description': '用于执行在本地环境运行的python代码'\n",
    "            },\n",
    "            'g': {\n",
    "                'type': 'string',\n",
    "                'description': '环境变量，可选参数，保持默认参数即可'\n",
    "            }\n",
    "        },\n",
    "        'required': ['py_code']\n",
    "    }\n",
    "}\n",
    "\n",
    "# GLM-4模型的Function calling封装为一个tools对象，同时说明当前Function性质\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": python_inter_function_info\n",
    "    }\n",
    "]\n",
    "\n",
    "# 打开并读取Markdown文件\n",
    "with open('telco_data_dictionary.md', 'r', encoding='utf-8') as f:\n",
    "    data_dictionary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723399b2-15f8-491b-939e-153c7235a097",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": data_dictionary},\n",
    "    {\"role\": \"user\", \"content\": \"请帮我读取telco_data数据集到本地python环境，并将其命名为data\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3eeb860-7190-4a46-98c9-9021a20d2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class glm_inter():\n",
    "    def __init__(self, \n",
    "                 api_key=os.getenv(\"ZHIPUAI_API_KEY\"),\n",
    "                 model='glm-4', \n",
    "                 system_content='',\n",
    "                 functions_list=None, \n",
    "                 tools = None,\n",
    "                 auto_run = True):\n",
    "        \n",
    "        self.api_key = api_key\n",
    "        self.model = model\n",
    "        if system_content == '':\n",
    "            self.messages = [{'role': 'system', 'content': '你是意为乐于助人的助手。'}]\n",
    "        else:\n",
    "            self.messages = [{'role': 'system', 'content': system_content}]\n",
    "        \n",
    "        self.functions_list = functions_list\n",
    "        self.tools = tools\n",
    "        self.auto_run = auto_run\n",
    "        \n",
    "    def chat(self, question=None):\n",
    "        head_str = \"▌ Model set to %s\" % self.model\n",
    "        display(Markdown(head_str))\n",
    "        \n",
    "        if question != None:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": question})\n",
    "            self.messages = check_code_run(messages = self.messages, \n",
    "                                           functions_list = self.functions_list, \n",
    "                                           tools = self.tools,\n",
    "                                           model = self.model, \n",
    "                                           auto_run = self.auto_run)\n",
    "        \n",
    "        else:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": '你好呀。'})\n",
    "            while True:\n",
    "                self.messages = check_code_run(messages = self.messages, \n",
    "                                               functions_list = self.functions_list, \n",
    "                                               tools = self.tools,\n",
    "                                               model = self.model, \n",
    "                                               auto_run = self.auto_run)\n",
    "                \n",
    "                user_input = input(\"您还有其他问题吗？(输入退出以结束对话): \")\n",
    "                if user_input == \"退出\":\n",
    "                    break\n",
    "                else:\n",
    "                    self.messages.append({\"role\": \"user\", \"content\": user_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8371173-f0b1-4eb4-8672-171e39f3c27f",
   "metadata": {},
   "source": [
    "- 多次Function calling自动调用说明。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8e6c92-8fdc-4f33-905e-c7a25d6717ea",
   "metadata": {},
   "source": [
    "这里首先需要补充介绍的是，对于Chat模型的Fucntion calling功能实现来说，面对一次调用外部函数无法完成需求的情况，Chat模型会自动启动第二次Function calling而无需人工设置，也就是说很多时候面对需要多步解决的问题（例如统计四张表的数据量是否一致），我们只需要将上一次的function response message输入给模型，模型就会根据当前外部函数是否已经完成需求，来判断是否需要再次调用function calling。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3931355-8d4c-4240-8817-26c9fb6b72b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 请帮我简单介绍telco_data数据集\n",
    "# 请帮我读取telco_data数据集到本地python环境，并将其命名为data\n",
    "# 请帮我查询data数据集数据缺失情况\n",
    "GI_test = glm_inter(system_content = data_dictionary, \n",
    "                    functions_list = [python_inter], \n",
    "                    tools = tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04579cdd-8c30-4b7f-867c-789099951c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "▌ Model set to glm-4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "你好，请问有什么我可以帮助你的吗？"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "您还有其他问题吗？(输入退出以结束对话):  结束\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "好的，如果有什么问题，随时可以来找我。再见！"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "您还有其他问题吗？(输入退出以结束对话):  退出\n"
     ]
    }
   ],
   "source": [
    "GI_test.chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523fc5d-fb7b-4337-90e4-b4b6d4871fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
